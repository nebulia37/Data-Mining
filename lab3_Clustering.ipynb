{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 5243 - Introduction to Data Mining\n",
    "## Homework 4: Clustering\n",
    "- Semester: Fall 2022\n",
    "- Instructor: Greg Ryslik\n",
    "- Section: Wednesday/Friday 12:45PM\n",
    "- Student Name: John Smith\n",
    "- Student.#: smith.3\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions and Helpful Hints:**\n",
    "- Consider putting all of your \"discussion\" text in markdown cells, not inline with code. That gives you more control over formatting. Markdown cheat sheet: https://www.markdownguide.org/cheat-sheet\n",
    "- Explain what you are doing, and why.  Explain what you found out or learned.\n",
    "- *Make sure you run your entire workbook before handing it in, so the output cells are populated.*\n",
    "- Follow the Section structure as much as possible - put your content where it is requested, so we can find your answers.\n",
    "- If you have questions on expectations or need clarification or guidance, please ask.  Post to Teams if it is a general question, so everyone benefits.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "In this lab, you will perform clustering on three datasets.  Your will choose suitable clustering algorithms, evaluate them on the datasets, and compare their performance.\n",
    "\n",
    "The objectives of this assignment are:\n",
    "1.\tUnderstand how to select and evaluate suitable off-the-shelf clustering algorithms based on the characteristics of a dataset and the outcomes you need.\n",
    "2.\tUnderstand how to tune and evaluate a clustering algorithm to achieve good performance.\n",
    "\n",
    "### Datasets:\n",
    "\n",
    "- The file **small_Xydf.csv** is a two-dimensional dataset with 200 records.  It contains columns X0, X1, and y.  The y column is the actual cluster number that was produced by the dataset generation algorithm.  Do not use it for the clustering algorithm.  It will be used to evaluate your clustering algorithm below.\n",
    "\n",
    "- The file **large1_Xydf.csv** is a two-dimensional dataset with 3000 records.  It contains columns X0, X1, and y.  The y column is the actual cluster number that was produced by the dataset generation algorithm.  Do not use it for the clustering algorithm.  It will be used to evaluate your clustering algorithm below.\n",
    "\n",
    "- The file **large2_Xydf.csv** is another two-dimensional dataset with 3000 records, and characteristics different from the “large1” dataset.  It contains columns X0, X1, and y.  The y column is the actual cluster number that was produced by the dataset generation algorithm.  Do not use it for the clustering algorithm.  It will be used to evaluate your clustering algorithm below.\n",
    "\n",
    "### Approach:\n",
    "\n",
    "This homework makes use of the Clustering Algorithms offered by the SciKitLearn Library.  Study the information at https://scikit-learn.org/stable/modules/clustering.html.  Follow the guidance in the individual sections below.\n",
    "\n",
    "### Collaboration:\n",
    "\n",
    "For this assignment, you should work as an individual. You may informally discuss ideas with classmates, to get advice on general Python usage, etc., but your work should be your own.  Please make use of Microsoft Teams!\n",
    "\n",
    "### What you need to turn in:\n",
    "\n",
    "1.\tCode\n",
    "\n",
    "-\tFor this homework, the code is the Jupyter Notebook.  Use the provided Jupyter Notebook template, and fill in the appropriate information.\n",
    "-\tThis homework requires you to use clustering algorithms in the SciKitLearn library.  You also may use common Python libraries for I/O, data manipulation, data visualization, etc. (e.g., NumPy, Pandas, MatPlotLib,…).  You may not use library operations that perform, in effect, the entire “core” computations for this homework. (e.g., If you happen to find a single function on the web that does essentially *all* of a major portion of the homework, you may not use it.)  When in doubt, ask the grader or instructor.\n",
    "-\tThe code must be written by you, and any significant code snips you found on the Internet and used to understand how to do your coding for the core functionality must be attributed.  (You do not need to attribute basic functionality – matrix operations, IO, etc.)\n",
    "-\tThe code must be commented sufficiently to allow a reader to understand the algorithm without reading the actual Python, step by step.\n",
    "-\tWhen in doubt, ask the grader or instructor.\n",
    "\n",
    "2.\tWritten Report\n",
    "-\tFor this homework, the report is the Jupyter Notebook.  The report should be well-written.  Please proof-read and remove spelling and grammar errors and typos.\n",
    "-\tThe report should discuss your analysis and observations. Key points and findings must be written in a style suitable for consumption by non-experts.  Present charts and graphs to support your observations. If you performed any data processing, cleaning, etc., please discuss it within the report.\n",
    "\n",
    "### Grading:\n",
    "\n",
    "1.\tOverall readability and organization of your report (10%) - Is it well organized and does the presentation flow in a logical manner; are there many grammar and spelling mistakes; do the charts/graphs relate to the text, etc.\n",
    "2.\tEvaluation of the KNN Clustering Algorithm on the Small Dataset (15%) – Is your configuration sound?  Have you made an effort to tune the algorithm for good performance?  Are your analyses and evaluations sound, and supported by suitable statistics and/or visualizations?\n",
    "3.\tEvaluation of the KNN Clustering Algorithm on the Large1 Dataset (15%) – Is your configuration sound?  Have you made an effort to tune the algorithm for good performance?  Are your analyses and evaluations sound, and supported by suitable statistics and/or visualizations?\n",
    "4.\tEvaluation of the KNN Clustering Algorithm on the Large2 Dataset (15%) – Is your configuration sound?  Have you made an effort to tune the algorithm for good performance?  Are your analyses and evaluations sound, and supported by suitable statistics and/or visualizations?\n",
    "5.\tEvaluation of the Second Clustering Algorithm on the Large2 Dataset (15%) – Is your choice of algorithm and your configuration sound?  Have you made an effort to tune the algorithm for good performance?  Are your analyses and evaluations sound, and supported by suitable statistics and/or visualizations?\n",
    "6.\tEvaluation of the Third Clustering Algorithm on the Large2 Dataset (15%) – Is your choice of algorithm and your configuration sound?  Have you made an effort to tune the algorithm for good performance?  Are your analyses and evaluations sound, and supported by suitable statistics and/or visualizations?\n",
    "7.\tComparison of the Three Clustering Algorithms (10%) - Is the comparison sound?  Did you choose a specific clustering algorithm as best and explain why?\n",
    "8.\tConclusions (5%) – Did you document your overall insights? \n",
    "\n",
    "### How to turn in your work on Carmen:\n",
    "\n",
    "**Please follow these instructions exactly** - it helps the grading process.  If you have questions, please ask.  Submit to Carmen any code that you used to process and analyze this data. You do not need to include the input data.  All the related files (code and/or report) except for the data should be archived in a **zip file (with no folder trees inside)** and submitted via Carmen.  The submitted file should be less than 5MB.  Use this naming convention: **HomeworkN_Surname_DotNumber.zip**\n",
    "\n",
    "### References and Acknowledgements:\n",
    "\n",
    "1.\thttps://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster\n",
    "2.\thttps://scikit-learn.org/stable/modules/clustering.html\n",
    "3.\thttps://docs.python.org/3/library/time.html\n",
    "4.\thttps://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linear_sum_assignment.html\n",
    "5.\thttps://gist.github.com/siolag161/dc6e42b64e1bde1f263b (using Hungarian Algorithm to match cluster labels - this is just an example)\n",
    "6.\thttps://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html (note that this is **mean** squared error)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: Overview\n",
    "- Insert a short description of the scope of this exercise, any supporting information, etc.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This exercise is mainly for me to master the realization and parameter selection of a variety of clustering methods. At the same time, through this exercise, I need to master the evaluation method of clustering effect and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: Setup\n",
    "- Add any needed imports, helper functions, etc., here.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# Section: 1 - Evaluate the **K-Means** Algorithm on the **Small** Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 1.1 - Calculate True Cluster Measures\n",
    "- Given that you know the true clusters (from column y in the original data), compute the true within-cluster WSS (also called “SSE” in the slides), the between-cluster BSS, and the Total SSE (WSS+BSS).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_cluster(title,X,y,size):\n",
    "    plt.figure(figsize=(size,size))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"X0\")\n",
    "    plt.ylabel(\"X1\")\n",
    "    plt.scatter(X[:,0],X[:,1],s=30,c=y)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "small_data = pd.read_csv(\"small_Xydf.csv\",header=0)\n",
    "small_data = small_data.iloc[:,1:]\n",
    "X = small_data[['X0','X1']].to_numpy()\n",
    "y = small_data['y'].to_numpy()\n",
    "true_y = small_data['y']\n",
    "plot_cluster(\"True clusters\",X,y,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.725226</td>\n",
       "      <td>-9.914383</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-12.362349</td>\n",
       "      <td>-5.284858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.179872</td>\n",
       "      <td>-6.274891</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.532723</td>\n",
       "      <td>-2.588246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.395447</td>\n",
       "      <td>-7.024462</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-9.729616</td>\n",
       "      <td>-1.549239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-0.633700</td>\n",
       "      <td>3.810304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-3.002052</td>\n",
       "      <td>4.381161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-9.138660</td>\n",
       "      <td>-5.167345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.143622</td>\n",
       "      <td>5.411479</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X0        X1  y\n",
       "0    -8.725226 -9.914383  2\n",
       "1   -12.362349 -5.284858  1\n",
       "2    -8.179872 -6.274891  2\n",
       "3    -9.532723 -2.588246  1\n",
       "4    -3.395447 -7.024462  2\n",
       "..         ...       ... ..\n",
       "195  -9.729616 -1.549239  1\n",
       "196  -0.633700  3.810304  0\n",
       "197  -3.002052  4.381161  0\n",
       "198  -9.138660 -5.167345  1\n",
       "199   0.143622  5.411479  0\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define WSS and calculate True WSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1506.532187125321"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wss(data_df):\n",
    "    # get the centroid X0 and X1 of 3 clusters\n",
    "    centroid = data_df.groupby('y').agg('mean')\n",
    "    def cal_wss_each(x):\n",
    "        return(pow(x['X0']-centroid.loc[x['y'],'X0'],2)+pow(x['X1']-centroid.loc[x['y'],'X1'],2))\n",
    "    wss_each = data_df.apply(lambda row : cal_wss_each(row), axis = 1)\n",
    "    return wss_each.sum()\n",
    "True_WSS = wss(small_data)  \n",
    "True_WSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'centroid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c88140330d64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcentroid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'centroid' is not defined"
     ]
    }
   ],
   "source": [
    "centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define BSS and calculate True BSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bss(data_df):\n",
    "    # get the centroid X0 and X1 of 3 clusters\n",
    "    centroid = data_df.groupby('y').agg('mean')\n",
    "    centroid['y'] = centroid.index\n",
    "    # get the mean of all X0 and X1\n",
    "    all_mean = data_df.mean()\n",
    "    cluster_size = data_df.y.value_counts()\n",
    "    def cal_bss_each(x):\n",
    "        return(cluster_size[x['y']]*pow(x['X0']-all_mean['X0'],2)+cluster_size[x['y']]*pow(x['X1']-all_mean['X1'],2))\n",
    "    bss_each = centroid.apply(lambda row : cal_bss_each(row), axis = 1)\n",
    "    return bss_each.sum()\n",
    "True_BSS = bss(small_data)\n",
    "True_BSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total SSE (WSS+BSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_sse(WSS,BSS):\n",
    "    return WSS+BSS\n",
    "True_total_SSE = total_sse(True_WSS, True_BSS)\n",
    "True_total_SSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 1.2 - Configure and Run the SciKitLearn K-Means Algorithm\n",
    "- Explain all configuration parameter values you chose, and why you chose them.\n",
    "- Run your algorithm for K=2, 3, 4.\n",
    "- For each run, compute the WSS, BSS, and Total SSE (WSS+BSS), and compute the running time (see Python Time reference – see %%time, time.process_time(), etc.).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import process_time\n",
    "\n",
    "range_clusters_k = [2,3,4]\n",
    "Pred_WSS = []\n",
    "Pred_BSS = []\n",
    "Pred_SSE = []\n",
    "Running_time = []\n",
    "\n",
    "for k in range_clusters_k:\n",
    "    start = process_time()\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    pred_y = kmeans.fit_predict(X)\n",
    "    end=process_time()\n",
    "    # first convert X to (200,2) then vstack with pred_y, we get (200,3), then transform it to (3,200)\n",
    "    data_array = np.vstack([X.T,pred_y]).T\n",
    "    data_df = pd.DataFrame(data_array, columns = ['X0','X1','y'])\n",
    "    end=process_time() \n",
    "    #calculate WSS\n",
    "    pred_wss=wss(data_df)\n",
    "    Pred_WSS.append(pred_wss)\n",
    "    #calculate BSS\n",
    "    pred_bss=bss(data_df)\n",
    "    Pred_BSS.append(pred_bss)\n",
    "    #calculate SSE\n",
    "    pred_sse=total_sse(pred_wss,pred_bss)\n",
    "    Pred_SSE.append(pred_sse)\n",
    "    #calculate running time\n",
    "    pred_time=end-start\n",
    "    Running_time.append(pred_time)\n",
    "    #print WSS,BSS,SSE,Time\n",
    "    print(\"K= \",k,\" WSS= \",pred_wss,\" BSS= \",pred_bss,\" SSE= \",pred_sse,\" Time= \",pred_time)\n",
    "\n",
    "# visuliazation\n",
    "fig = plt.figure(figsize=(14,10))\n",
    "fig.add_subplot(221)\n",
    "plt.plot(range_clusters_k, Pred_WSS, 'p-',label='WSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('WSS')\n",
    "plt.legend()\n",
    "fig.add_subplot(222)\n",
    "plt.plot(range_clusters_k, Pred_BSS, 'p-',label='BSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('BSS')\n",
    "plt.legend()\n",
    "fig.add_subplot(223)\n",
    "plt.plot(range_clusters_k, Pred_SSE, 'p-',label='BSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.legend()\n",
    "fig.add_subplot(224)\n",
    "plt.plot(range_clusters_k, Running_time,'p-',label='Time')\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(\"Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 1.3 - For the K=3 Case Above:\n",
    "- Create a scatterplot, overlaying the true cluster with the cluster produced by your algorithm.  (Or alternatively, create two side by side scatterplots).\n",
    "- Create a cross tabulation matrix (i.e., confusion matrix) comparing the true and assigned clusters, and the basic measures (precision, recall, F1, accuracy, etc. - see classification_report).  Note that you may need to \"match up\" the true and assigned cluster labels.  See the linear-sum-assignment and Hungarian algorithm references, for example.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = KMeans(n_clusters=3, random_state=0).fit_predict(X)\n",
    "plot_cluster(\"True clusters\",X,y,4)\n",
    "plot_cluster(\"Predicted clusters\",X,pred_y,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from munkres import Munkres\n",
    "\n",
    "def make_cost_matrix(c1, c2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    uc1 = np.unique(c1)\n",
    "    uc2 = np.unique(c2)\n",
    "    l1 = uc1.size\n",
    "    l2 = uc2.size\n",
    "    #assert(l1 == l2 and np.all(uc1 == uc2))\n",
    "\n",
    "    m = np.ones([l1, l2])\n",
    "    for i in range(l1):\n",
    "        it_i = np.nonzero(c1[i] == uc1[i])[0]\n",
    "        for j in range(l2):\n",
    "            it_j = np.nonzero(c2[j] == uc2[j])[0]\n",
    "            m_ij = np.intersect1d(it_j, it_i)\n",
    "            m[i,j] =  -m_ij.size\n",
    "    return m\n",
    "\n",
    "def translate_clustering(clt, mapper):\n",
    "    return np.array([ mapper[i] for i in clt ])\n",
    "\n",
    "def accuracy(cm):\n",
    "    \"\"\"computes accuracy from confusion matrix\"\"\"\n",
    "    return np.trace(cm, dtype=float) / np.sum(cm)\n",
    "\n",
    "def calculate_cost_matrix(C, n_clusters):\n",
    "    cost_matrix = np.zeros((n_clusters, n_clusters))\n",
    "\n",
    "    # cost_matrix[i,j] will be the cost of assigning cluster i to label j\n",
    "    for j in range(n_clusters):\n",
    "        s = np.sum(C[:,j]) # number of examples in cluster i\n",
    "        for i in range(n_clusters):\n",
    "            t = C[i,j]\n",
    "            cost_matrix[j,i] = s-t\n",
    "    return cost_matrix\n",
    "\n",
    "def tabulation_matrix(y_true,y_pred):\n",
    "    \"\"\"entry point\"\"\"\n",
    "    \n",
    "    num_labels = len(np.unique(y_true))\n",
    "    n_clusters = len(np.unique(y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(num_labels)) # gets the confusion matrix\n",
    "    print (\"---------------------\\nold confusion matrix:\\n\" \\\n",
    "          \" %s\\naccuracy: %.2f\" % (str(cm), accuracy(cm)))\n",
    "\n",
    "    #cost_matrix = make_cost_matrix(y_pred, y_true)\n",
    "    cost_matrix = calculate_cost_matrix(cm, num_labels)\n",
    "    print('cost matrix:\\n',cost_matrix)\n",
    "\n",
    "    m = Munkres()\n",
    "    indexes = m.compute(cost_matrix)\n",
    "    print('index:',indexes)\n",
    "    mapper = { old: new for (old, new) in indexes }\n",
    "\n",
    "    print (\"---------------------\\nmapping:\")\n",
    "    for old, new in mapper.items():\n",
    "        print (\"map: %s --> %s\" %(old, new))\n",
    "\n",
    "    new_labels = translate_clustering(y_pred, mapper)\n",
    "   \n",
    "    \n",
    "    new_cm = confusion_matrix(y_true, new_labels, labels=range(num_labels))\n",
    "    print (\"---------------------\\nnew confusion matrix:\\n\" \\\n",
    "          \" %s\\naccuracy: %.2f\" % (str(new_cm), accuracy(new_cm)))\n",
    "    \n",
    "tabulation_matrix(y,pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the true and assigned clusters, and the basic measures (precision, recall, F1, accuracy, etc. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classification_report(y, pred_y, labels=None, target_names=None, sample_weight=None, digits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 1.4 - Record Your Observations\n",
    "- What do you observe or conclude from these experiments?\n",
    "- Which is your “preferred” clustering (K value in particular), and why?\n",
    "- Support this with statistics and/or graphs.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### observation\n",
    "- Total SSE is a contant.\n",
    "- The larger the K, the longer the program will run.\n",
    "- The larger K is, the smaller WSS is.\n",
    "\n",
    "### K=3 is best\n",
    "- When K is at 3, WSS produces an inflection point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# record WSS for every value of K\n",
    "Pred_WSS = []\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    pred_y = kmeans.fit_predict(X)\n",
    "    end=process_time()\n",
    "    # first convert X to (200,2) then vstack with pred_y, we get (200,3), then transform it to (3,200)\n",
    "    data_array = np.vstack([X.T,pred_y]).T\n",
    "    data_df = pd.DataFrame(data_array, columns = ['X0','X1','y'])\n",
    "    pred_wss=wss(data_df)\n",
    "    Pred_WSS.append(pred_wss)\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.plot(range_n_clusters, Pred_WSS,'p-',label='WSS')\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"WSS\")\n",
    "plt.title(\"WSS\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# Section: 2 - Evaluate the **K-Means** Algorithm on the **Large1** Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.1 - Calculate True Cluster Measures\n",
    "- Given that you know the true clusters (from column y in the original data), compute the true within-cluster WSS (also called “SSE” in the slides), the between-cluster BSS, and the Total SSE (WSS+BSS).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_data = pd.read_csv('large1_Xydf.csv')\n",
    "L1_data = L1_data.iloc[:,1:]\n",
    "true_y=L1_data['y']\n",
    "X = L1_data[['X0','X1']].to_numpy()\n",
    "y = L1_data['y'].to_numpy()\n",
    "plot_cluster(\"True Clusters\", X, y, 4)\n",
    "L1_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate True WSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_WSS=wss(L1_data)\n",
    "True_WSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate True BSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_BSS=bss(L1_data)\n",
    "True_BSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate True Total SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_SSE = total_sse(True_WSS, True_BSS)\n",
    "True_SSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.2 - Configure and Run the SciKitLearn K-Means Algorithm\n",
    "- Explain all configuration parameter values you chose, and why you chose them.\n",
    "- Run your algorithm for K=6, 8, 10.\n",
    "- For each run, compute the WSS, BSS, and Total SSE (WSS+BSS), and compute the running time (see Python Time reference – see %%time, time.process_time(), etc.).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_clusters_k = [6,8,10]\n",
    "Pred_WSS = []\n",
    "Pred_BSS = []\n",
    "Pred_SSE = []\n",
    "Running_time = []\n",
    "\n",
    "for k in range_clusters_k:\n",
    "    start = process_time()\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    pred_y = kmeans.fit_predict(X)\n",
    "    end=process_time() \n",
    "    # first convert X to (200,2) then vstack with pred_y, we get (200,3), then transform it to (3,200)\n",
    "    data_array = np.vstack([X.T,pred_y]).T\n",
    "    data_df = pd.DataFrame(data_array, columns = ['X0','X1','y'])\n",
    "    #calculate WSS\n",
    "    pred_wss=wss(data_df)\n",
    "    Pred_WSS.append(pred_wss)\n",
    "    #calculate BSS\n",
    "    pred_bss=bss(data_df)\n",
    "    Pred_BSS.append(pred_bss)\n",
    "    #calculate SSE\n",
    "    pred_sse=total_sse(pred_wss,pred_bss)\n",
    "    Pred_SSE.append(pred_sse)\n",
    "    #calculate running time\n",
    "    pred_time=end-start\n",
    "    Running_time.append(pred_time)\n",
    "    #print WSS,BSS,SSE,Time\n",
    "    print(\"K= \",k,\" WSS= \",pred_wss,\" BSS= \",pred_bss,\" SSE= \",pred_sse,\" Time= \",pred_time)\n",
    "\n",
    "# visuliazation\n",
    "fig = plt.figure(figsize=(14,10))\n",
    "fig.add_subplot(221)\n",
    "plt.plot(range_clusters_k, Pred_WSS, 'p-',label='WSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('WSS')\n",
    "plt.legend()\n",
    "fig.add_subplot(222)\n",
    "plt.plot(range_clusters_k, Pred_BSS, 'p-',label='BSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('BSS')\n",
    "plt.legend()\n",
    "fig.add_subplot(223)\n",
    "plt.plot(range_clusters_k, Pred_SSE, 'p-',label='BSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.legend()\n",
    "fig.add_subplot(224)\n",
    "plt.plot(range_clusters_k, Running_time,'p-',label='Time')\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(\"Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.3 - For the K=8 Case Above:\n",
    "- Create a scatterplot, overlaying the true cluster with the cluster produced by your algorithm.  (Or alternatively, create two side by side scatterplots).\n",
    "- Create a cross tabulation matrix (i.e., confusion matrix) comparing the true and assigned clusters, and the basic measures (precision, recall, F1, accuracy, etc. - see classification_report).  Note that you may need to \"match up\" the true and assigned cluster labels.  See the linear-sum-assignment and Hungarian algorithm references, for example.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = KMeans(n_clusters=3, random_state=0).fit_predict(X)\n",
    "plot_cluster(\"True clusters\",X,y,4)\n",
    "plot_cluster(\"Predicted clusters\",X,pred_y,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross tabulation matrix comparing the true and assigned clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabulation_matrix(y,pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the true and assigned clusters, and the basic measures (precision, recall, F1, accuracy, etc. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y, pred_y, labels=None, target_names=None, sample_weight=None, digits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.4 - Record Your Observations\n",
    "- What do you observe or conclude from these experiments?\n",
    "- Which is your “preferred” clustering (K value in particular), and why?\n",
    "- Support this with statistics and/or graphs.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Observation:\n",
    "\n",
    "- Total SSE is a contant.\n",
    "- The larger the K, the longer the program will run.\n",
    "- The larger K is, the smaller WSS is.\n",
    "\n",
    "### K=7 is best\n",
    "\n",
    "- When K is at 7, WSS produces an inflection point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "# record WSS for every value of K\n",
    "Pred_WSS = []\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    #iterating through cluster sizes\n",
    "    clusterer = KMeans(n_clusters = n_clusters, random_state=42)\n",
    "    pred_y = clusterer.fit_predict(X)\n",
    "    data_array = np.vstack([X.T,pred_y]).T\n",
    "    data_df = pd.DataFrame(data_array, columns = ['X0','X1','y']) \n",
    "    #calculate WSS\n",
    "    pred_wss=wss(data_df)\n",
    "    Pred_WSS.append(pred_wss)\n",
    "fig = plt.figure()\n",
    "plt.plot(range_n_clusters, Pred_WSS,'p-',label='WSS')\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"WSS\")\n",
    "plt.title(\"WSS\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# Section: 3 - Evaluate the **K-Means** Algorithm on the **Large2** Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.1 - Calculate True Cluster Measures\n",
    "- Given that you know the true clusters (from column y in the original data), compute the true within-cluster WSS (also called “SSE” in the slides), the between-cluster BSS, and the Total SSE (WSS+BSS).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate True WSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_WSS=wss(L2_data)\n",
    "True_WSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate True BSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_BSS=bss(L2_data)\n",
    "True_BSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate True Total SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_SSE = total_sse(True_WSS, True_BSS)\n",
    "True_SSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.2 - Configure and Run the SciKitLearn K-Means Algorithm\n",
    "- Explain all configuration parameter values you chose, and why you chose them.\n",
    "- Run your algorithm for K=2, 3, 4.\n",
    "- For each run, compute the WSS, BSS, and Total SSE (WSS+BSS), and compute the running time (see Python Time reference – see %%time, time.process_time(), etc.).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_data = pd.read_csv('large2_Xydf.csv')\n",
    "L2_data = L2_data.iloc[:,1:]\n",
    "true_y=L2_data['y']\n",
    "X = L2_data[['X0','X1']].to_numpy()\n",
    "y = L2_data['y'].to_numpy()\n",
    "plot_cluster(\"True Clusters\", X, y, 4)\n",
    "L2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_clusters_k = [2,3,4]\n",
    "Pred_WSS = []\n",
    "Pred_BSS = []\n",
    "Pred_SSE = []\n",
    "Running_time = []\n",
    "\n",
    "for k in range_clusters_k:\n",
    "    start = process_time()\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    pred_y = kmeans.fit_predict(X)\n",
    "    end=process_time() \n",
    "    # first convert X to (200,2) then vstack with pred_y, we get (200,3), then transform it to (3,200)\n",
    "    data_array = np.vstack([X.T,pred_y]).T\n",
    "    data_df = pd.DataFrame(data_array, columns = ['X0','X1','y'])\n",
    "    #calculate WSS\n",
    "    pred_wss=wss(data_df)\n",
    "    Pred_WSS.append(pred_wss)\n",
    "    #calculate BSS\n",
    "    pred_bss=bss(data_df)\n",
    "    Pred_BSS.append(pred_bss)\n",
    "    #calculate SSE\n",
    "    pred_sse=total_sse(pred_wss,pred_bss)\n",
    "    Pred_SSE.append(pred_sse)\n",
    "    #calculate running time\n",
    "    pred_time=end-start\n",
    "    Running_time.append(pred_time)\n",
    "    #print WSS,BSS,SSE,Time\n",
    "    print(\"K= \",k,\" WSS= \",pred_wss,\" BSS= \",pred_bss,\" SSE= \",pred_sse,\" Time= \",pred_time)\n",
    "\n",
    "# visuliazation\n",
    "fig = plt.figure(figsize=(14,10))\n",
    "fig.add_subplot(221)\n",
    "plt.plot(range_clusters_k, Pred_WSS, 'p-',label='WSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('WSS')\n",
    "plt.legend()\n",
    "fig.add_subplot(222)\n",
    "plt.plot(range_clusters_k, Pred_BSS, 'p-',label='BSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('BSS')\n",
    "plt.legend()\n",
    "fig.add_subplot(223)\n",
    "plt.plot(range_clusters_k, Pred_SSE, 'p-',label='BSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.legend()\n",
    "fig.add_subplot(224)\n",
    "plt.plot(range_clusters_k, Running_time,'p-',label='Time')\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(\"Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.3 - For the K=2 Case Above:\n",
    "- Create a scatterplot, overlaying the true cluster with the cluster produced by your algorithm.  (Or alternatively, create two side by side scatterplots).\n",
    "- Create a cross tabulation matrix (i.e., confusion matrix) comparing the true and assigned clusters, and the basic measures (precision, recall, F1, accuracy, etc. - see classification_report).  Note that you may need to \"match up\" the true and assigned cluster labels.  See the linear-sum-assignment and Hungarian algorithm references, for example.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = KMeans(n_clusters = 2, random_state=42)\n",
    "pred_y = clusterer.fit_predict(X)\n",
    "plot_cluster(\"True Clusters\", X, y, 5)\n",
    "plot_cluster(\"Pred Clusters K=2\", X, pred_y, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross tabulation matrix comparing the true and assigned clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabulation_matrix(y,pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the true and assigned clusters, and the basic measures (precision, recall, F1, accuracy, etc. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y, pred_y, labels=None, target_names=None, sample_weight=None, digits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.4 - Record Your Observations\n",
    "- What do you observe or conclude from these experiments?\n",
    "- Which is your “preferred” clustering (K value in particular), and why?\n",
    "- Support this with statistics and/or graphs.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Observation:\n",
    "\n",
    "- Limitations of K-means: Non-globular Shapes\n",
    "\n",
    "### K=6 is best\n",
    "\n",
    "- When K is at 6, WSS produces an inflection point.Overcoming Limitations of K-means: Non-globular Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# record WSS for every value of K\n",
    "Pred_WSS = []\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    #iterating through cluster sizes\n",
    "    clusterer = KMeans(n_clusters = n_clusters, random_state=42)\n",
    "    pred_y = clusterer.fit_predict(X)\n",
    "    data_array = np.vstack([X.T,pred_y]).T\n",
    "    data_df = pd.DataFrame(data_array, columns = ['X0','X1','y']) \n",
    "    #calculate WSS\n",
    "    pred_wss=wss(data_df)\n",
    "    Pred_WSS.append(pred_wss)\n",
    "fig = plt.figure()\n",
    "plt.plot(range_n_clusters, Pred_WSS,'p-',label='WSS')\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"WSS\")\n",
    "plt.title(\"WSS\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 4 - Evaluate a **Second** Clustering Algorithm on the **Large2** Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 4.1 - Choose a Clustering Algorithm from the SciKitLearn Library  \n",
    "- Explain why you chose it.\n",
    "- See the SciKitLearn references.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Clustering\n",
    "\n",
    "- The process does not require too many assumptions on data structure. For example, Kmeans requires data to be convex set.\n",
    "- By constructing sparse Similarity graph, it can significantly outperform other algorithms in computing speed for larger data sets.\n",
    "- As spectral clustering is a graph cutting process, there is no clustering of discrete clusters like kmesns clustering.\n",
    "- There is no need to make assumptions about the probability distribution of data like GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 4.2 - Configure and Run the Algorithm\n",
    "- Do this for (at least) two variations of the configuration settings (if any).  Explain all configuration parameter values you chose, and why you chose them.\n",
    "- For Each Run:\n",
    "1. Compute the within-cluster WSS, the between-cluster BSS, and the Total SSE (WSS+BSS), and compute the running time.\n",
    "2. Create a scatterplot, overlaying the true cluster with the cluster produced by your algorithm.  (Or alternatively, create two side by side scatterplots).\n",
    "3. Create a cross tabulation matrix (i.e., confusion matrix) comparing the true and assigned clusters, and the basic measures (precision, recall, F1, accuracy, etc. - see classification_report).  Note that you may need to \"match up\" the true and assigned cluster labels.  See the linear-sum-assignment and Hungarian algorithm references, for example.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_clusters_k = [2,3,4]\n",
    "Pred_WSS = []\n",
    "Pred_BSS = []\n",
    "Pred_SSE = []\n",
    "Running_time = []\n",
    "\n",
    "for k in range_clusters_k:\n",
    "    start = process_time()\n",
    "    clusters = SpectralClustering(n_clusters= k)\n",
    "    pred_y = clusters.fit_predict(X)\n",
    "    end=process_time() \n",
    "    # first convert X to (200,2) then vstack with pred_y, we get (200,3), then transform it to (3,200)\n",
    "    data_array = np.vstack([X.T,pred_y]).T\n",
    "    data_df = pd.DataFrame(data_array, columns = ['X0','X1','y'])\n",
    "    #calculate WSS\n",
    "    pred_wss=wss(data_df)\n",
    "    Pred_WSS.append(pred_wss)\n",
    "    #calculate BSS\n",
    "    pred_bss=bss(data_df)\n",
    "    Pred_BSS.append(pred_bss)\n",
    "    #calculate SSE\n",
    "    pred_sse=total_sse(pred_wss,pred_bss)\n",
    "    Pred_SSE.append(pred_sse)\n",
    "    #calculate running time\n",
    "    pred_time=end-start\n",
    "    Running_time.append(pred_time)\n",
    "    #print WSS,BSS,SSE,Time\n",
    "    plot_cluster(\"Pred Clusters\", X, pred_y, 5)\n",
    "    print(\"K= \",k,\" WSS= \",pred_wss,\" BSS= \",pred_bss,\" SSE= \",pred_sse,\" Time= \",pred_time)\n",
    "\n",
    "# visuliazation\n",
    "fig = plt.figure(figsize=(14,10))\n",
    "fig.add_subplot(221)\n",
    "plt.plot(range_clusters_k, Pred_WSS, 'p-',label='WSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('WSS')\n",
    "plt.legend()\n",
    "fig.add_subplot(222)\n",
    "plt.plot(range_clusters_k, Pred_BSS, 'p-',label='BSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('BSS')\n",
    "plt.legend()\n",
    "fig.add_subplot(223)\n",
    "plt.plot(range_clusters_k, Pred_SSE, 'p-',label='BSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.legend()\n",
    "fig.add_subplot(224)\n",
    "plt.plot(range_clusters_k, Running_time,'p-',label='Time')\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(\"Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross tabulation matrix comparing the true and assigned clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = SpectralClustering(n_clusters = 2)\n",
    "y_pred = clusterer.fit_predict(X)\n",
    "tabulation_matrix(y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the true and assigned clusters, and the basic measures (precision, recall, F1, accuracy, etc. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y, y_pred, labels=None, target_names=None, sample_weight=None, digits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 4.3 - Record Your Observations\n",
    "- What do you observe or conclude from these experiments?\n",
    "- Which is your “preferred” clustering (configuration settings, if any), and why?\n",
    "- Support this with statistics and/or graphs.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "- Larger num_clusters not always produces the smaller WSS!!!!\n",
    "- Increasing num_clusters can overcoming Limitations of K-means: Non-globular Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K=4 is best\n",
    "\n",
    "- When K is at 4, WSS produces an inflection point.Overcoming Limitations of K-means: Non-globular Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# record WSS for every value of K\n",
    "Pred_WSS = []\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    #iterating through cluster sizes\n",
    "    clusterer = SpectralClustering(n_clusters = n_clusters, random_state=42)\n",
    "    pred_y = clusterer.fit_predict(X)\n",
    "    data_array = np.vstack([X.T,pred_y]).T\n",
    "    data_df = pd.DataFrame(data_array, columns = ['X0','X1','y']) \n",
    "    #calculate WSS\n",
    "    pred_wss=wss(data_df)\n",
    "    Pred_WSS.append(pred_wss)\n",
    "fig = plt.figure()\n",
    "plt.plot(range_n_clusters, Pred_WSS,'p-',label='WSS')\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"WSS\")\n",
    "plt.title(\"WSS\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 5 - Evaluate a **Third** Clustering Algorithm on the **Large2** Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 5.1 - Choose a Clustering Algorithm from the SciKitLearn Library  \n",
    "- Explain why you chose it.\n",
    "- See the SciKitLearn references.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering\n",
    "- One of the advantages of the algorithm is that the clustering of data sets can be displayed at different scales (levels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 5.2 - Configure and Run the Algorithm\n",
    "- Do this for (at least) two variations of the configuration settings (if any).  Explain all configuration parameter values you chose, and why you chose them.\n",
    "- For Each Run:\n",
    "1. Compute the within-cluster WSS, the between-cluster BSS, and the Total SSE (WSS+BSS), and compute the running time.\n",
    "2. Create a scatterplot, overlaying the true cluster with the cluster produced by your algorithm.  (Or alternatively, create two side by side scatterplots).\n",
    "3. Create a cross tabulation matrix (i.e., confusion matrix) comparing the true and assigned clusters, and the basic measures (precision, recall, F1, accuracy, etc. - see classification_report).  Note that you may need to \"match up\" the true and assigned cluster labels.  See the linear-sum-assignment and Hungarian algorithm references, for example.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set n_clusters=2, 3, 4; Compute WSS, BSS, Total SSE (WSS+BSS), and running time; Create scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_clusters_k = [2,3,4]\n",
    "Pred_WSS = []\n",
    "Pred_BSS = []\n",
    "Pred_SSE = []\n",
    "Running_time = []\n",
    "\n",
    "for k in range_clusters_k:\n",
    "    start = process_time()\n",
    "    clusters = AgglomerativeClustering(n_clusters= k)\n",
    "    pred_y = clusters.fit_predict(X)\n",
    "    end=process_time() \n",
    "    # first convert X to (200,2) then vstack with pred_y, we get (200,3), then transform it to (3,200)\n",
    "    data_array = np.vstack([X.T,pred_y]).T\n",
    "    data_df = pd.DataFrame(data_array, columns = ['X0','X1','y'])\n",
    "    #calculate WSS\n",
    "    pred_wss=wss(data_df)\n",
    "    Pred_WSS.append(pred_wss)\n",
    "    #calculate BSS\n",
    "    pred_bss=bss(data_df)\n",
    "    Pred_BSS.append(pred_bss)\n",
    "    #calculate SSE\n",
    "    pred_sse=total_sse(pred_wss,pred_bss)\n",
    "    Pred_SSE.append(pred_sse)\n",
    "    #calculate running time\n",
    "    pred_time=end-start\n",
    "    Running_time.append(pred_time)\n",
    "    #print WSS,BSS,SSE,Time\n",
    "    plot_cluster(\"Pred Clusters\", X, pred_y, 5)\n",
    "    print(\"K= \",k,\" WSS= \",pred_wss,\" BSS= \",pred_bss,\" SSE= \",pred_sse,\" Time= \",pred_time)\n",
    "\n",
    "# visuliazation\n",
    "fig = plt.figure(figsize=(14,10))\n",
    "fig.add_subplot(221)\n",
    "plt.plot(range_clusters_k, Pred_WSS, 'p-',label='WSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('WSS')\n",
    "plt.legend()\n",
    "fig.add_subplot(222)\n",
    "plt.plot(range_clusters_k, Pred_BSS, 'p-',label='BSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('BSS')\n",
    "plt.legend()\n",
    "fig.add_subplot(223)\n",
    "plt.plot(range_clusters_k, Pred_SSE, 'p-',label='BSS')\n",
    "plt.xlabel('Num of clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.legend()\n",
    "fig.add_subplot(224)\n",
    "plt.plot(range_clusters_k, Running_time,'p-',label='Time')\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(\"Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross tabulation matrix comparing the true and assigned clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = AgglomerativeClustering(n_clusters = 2)\n",
    "y_pred = clusterer.fit_predict(X)\n",
    "tabulation_matrix(y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the true and assigned clusters, and the basic measures (precision, recall, F1, accuracy, etc. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y, y_pred, labels=None, target_names=None, sample_weight=None, digits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 5.3 - Record Your Observations\n",
    "- What do you observe or conclude from these experiments?\n",
    "- Which is your “preferred” clustering (configuration settings, if any), and why?\n",
    "- Support this with statistics and/or graphs.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "- Total SSE is a contant.\n",
    "- The larger the num_clusters, the longer the program will run.\n",
    "- The larger num_clusters is, the smaller WSS is.\n",
    "- Increasing num_clusters can overcoming Limitations of K-means: Non-globular Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K=4 is best\n",
    "\n",
    "- When K is at 4, WSS produces an inflection point.Overcoming Limitations of K-means: Non-globular Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# record WSS for every value of K\n",
    "Pred_WSS = []\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    #iterating through cluster sizes\n",
    "    clusterer = AgglomerativeClustering(n_clusters = n_clusters)\n",
    "    pred_y = clusterer.fit_predict(X)\n",
    "    data_array = np.vstack([X.T,pred_y]).T\n",
    "    data_df = pd.DataFrame(data_array, columns = ['X0','X1','y']) \n",
    "    #calculate WSS\n",
    "    pred_wss=wss(data_df)\n",
    "    Pred_WSS.append(pred_wss)\n",
    "fig = plt.figure()\n",
    "plt.plot(range_n_clusters, Pred_WSS,'p-',label='WSS')\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"WSS\")\n",
    "plt.title(\"WSS\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 6 - Comparison of the Three Clustering Algorithms on the **Large2** Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 6.1 - Compare Their Performance\n",
    "- What was their relative performance (quality and timing), and their performance versus the true clustering?\n",
    "- What characteristics of the data might impact the clustering algorithms' performance?\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative performance and performance versus the true clustering\n",
    "- Qulity: Agglomerative(wss:1378)> Spectral(wss:1315)> KMeans(wss:1310)\n",
    "- Time: Spectral > Agglomerative > KMeans\n",
    "- Performance versus the true clustering: Agglomerative(0.83)> Spectral(0.78)> KMeans(0.75)\n",
    "\n",
    "### What characteristics of the data might impact the clustering algorithms' performance?\n",
    "\n",
    "### Size:\n",
    "- Each category in the three datasets is similar in size, so the classification works well. If the category sizes are not similar, the effect will be different.\n",
    "\n",
    "### Density:\n",
    "- Each category in the three datasets is similar in density, so the classification works well. If the category density are not similar, the effect will be different.\n",
    "\n",
    "### Non-globular Shapes:\n",
    "- The clustering effect of the third data set is not very good due to the Non-globular Shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 6.2 - Choose a Best Clustering Algorithm\n",
    "- Choose one of the three clustering algorithm as best and explain why.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose one of the three clustering algorithm as best and explain why.\n",
    "- I think K-means is the Best:\n",
    "- Simple and fast , which is one of the important reasons why k-means is used most in the industry. \n",
    "- You only need to change k when you call a parameter. And the choice of k is easy. \n",
    "- The principle of the algorithm is simple and explicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 7 - Conclusions\n",
    "- Write a paragraph on what you discovered or learned from this homework.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I learned the realization of three clustering methods and understood the meaning of each parameter.\n",
    "- I learned how to calculate WSS, BSS and SSE methods, as well as calculate program running time.\n",
    "- I understand that different characteristics of data will affect the clustering effect.\n",
    "- I learned how to evaluate the clustering effect by comparing it with standard clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### END-OF-SUBMISSION\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
